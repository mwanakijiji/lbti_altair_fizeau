#PBS -q standard
#PBS -l select=1:ncpus=16:mem=96gb
### Specify a name for the job
#PBS -N fizeau_altair
### Specify the group name
#PBS -W group_list=ktmorz
### Used if job requires partial node only
#PBS -l place=pack:shared
### CPUtime required in hhh:mm:ss.
### Leading 0's can be omitted e.g 48:0:0 sets 48 hours
#PBS -l cput=96:00:00
### Walltime is how long your job will run
#PBS -l walltime=24:00:00
### send email when done
#PBS -M spalding@email.arizona.edu

### start timestamp
echo "Start time"
date

### set variables: filenames of the data tarball and Singularity container
export DATA_TARBALL=altair_200204_10frames.tar.gz
export RESULTS_TARBALL=results.tar
export SING_FILE=lbti_altair_fizeau_latest.sif

### load python 3.6.5
module load python/3

### load Singularity
module load singularity

### check if 500 Gb of storage are available in /tmp
echo $HOSTNAME
echo "Check if /tmp has 500GB of storage available"
available_space=$(df -h /tmp | tail -n +2 | awk '{print $4}' | sed 's/.$//')
if [ $available_space -gt 500 ]
then
   echo "There is enough storage"
   echo $available_space GB
   date

   ### get current (home) directory
   export HOME_DIR=$PWD

   ### make a new /tmp/ directory on the compute node
   rm -fr /tmp/$USER
   mkdir /tmp/$USER

   ### copy tarball into the /tmp/ directory
   ### (for 180507 Altair data, the top-level directory produced in the untarring
   ### is /180507_fizeau_altair/ and NOT /vol_c/)
   cp /xdisk/$USER/$DATA_TARBALL /tmp/$USER
   cd /tmp/$USER
   echo "Changed to tarball and Singularity file directory"
   pwd
   echo "---"
   date

   ### unpack data
   echo "Unpacking data in directory"
   pwd
   echo "---"
   tar -xvf $DATA_TARBALL
   echo "Tarball extracted"
   date
   echo "---"

   ### pull the Singularity file (which contains the code)
   singularity pull --name $SING_FILE shub://mwanakijiji/lbti_altair_fizeau:latest
   echo "Singularity file pulled in directory"
   pwd
   date
   echo "---"

   ### BEGIN TEST
   echo "List of files in directory Singularity file was pulled to"
   ls
   echo "---"
   echo "List of files in /xdisk/user/ dir:"
   ls /xdisk/$USER
   echo "---"
   echo "List of files in /tmp/user/ dir:"
   ls /tmp/$USER
   echo "---"
   ### END TEST

   ### (decoupling the data and the script avoids requiring new
   ### tarring each time the script is edited)

   ### run Singularity container (bind syntax is host:container)
   ### data files -> /tmp/$USER/180507_fizeau_altair:/vol_c/180507_fizeau_altair
   ### code files -> (is it necessary to bind this?) :/modules
   singularity exec \
    --bind /tmp/$USER/180507_fizeau_altair:/vol_c/180507_fizeau_altair \
    /tmp/$USER/$SING_FILE \
    python3 /altair_pipeline.py

   echo "Ran Singularity:"
   date
   echo "---"

   ### create tar archive of the results in /tmp/, and leave it in /xdisk/
   ### directory
   echo "Tarring outputs"
   tar -czf $RESULTS_TARBALL \
    --exclude='/tmp/$USER/180507_fizeau_altair/pipeline_0[0-6]*' \
    /tmp/$USER/180507_fizeau_altair
   echo "Done tarring output:"
   date
   echo "---"
   cp $RESULTS_TARBALL /xdisk/$USER
   echo "Done copying output to /xdisk/:"
   date
   echo "---"

   ### delete the stuff remaining in /tmp/
   rm -fr /tmp/$USER
   echo "Deleted stuff in the /tmp/ directory:"

   ### timestamp end
   date

else

  echo "There is not enough storage"
  echo $available_space GB
fi
