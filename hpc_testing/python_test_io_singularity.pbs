### Your job will use 1 node, 28 cores, and 168gb of memory total.
#PBS -q debug
#PBS -l select=1:ncpus=1:mem=168gb:pcmem=6gb
### Specify a name for the job
#PBS -N test_python_io
### Specify the group name
#PBS -W group_list=ktmorz
### Used if job requires partial node only
#PBS -l place=pack:shared
### CPUtime required in hhh:mm:ss.
### Leading 0's can be omitted e.g 48:0:0 sets 48 hours
#PBS -l cput=00:03:00
### Walltime is how long your job will run
#PBS -l walltime=00:03:00
### send email when done
#PBS -M spalding@email.arizona.edu

### load python 3.6.5
module load python/3

### check if 500 Gb of storage are available in /tmp
echo $HOSTNAME
echo "Check if /tmp has 500GB of storage available"
available_space=$(df -h /tmp | tail -n +2 | awk '{print $4}' | sed 's/.$//')
if [ $available_space -gt 500 ]
then
   echo "There is enough storage"
   echo $available_space GB

   ### get current directory
   export start_dir=$PWD

   ### copy tarball into the /tmp/ directory on the same node
   cp /xdisk/spalding/vol_c/altair_tar.tar.gz /tmp/$USER
   cd /tmp/$USER

   ### unpack data
   tar -xzvf altair_tar.tar.gz

   ### move back to start directory
   ### (decoupling the data and the script avoids requiring new
   ### tarring each time the script is edited)
   cd start_dir

   echo "Back in start directory"

   ### run Singularity container
   ### singularity exec --bind ${HOME}/lbti_altair_fizeau/modules:/modules --bind /vol_c:/vol_c [CONTAINER NAME].simg python python_io_test.py

   ### run placeholder executable
   ### python3 python_io.py

   ### timestamp end
   date

else

  echo "There is not enough storage"
  echo $available_space GB
fi
